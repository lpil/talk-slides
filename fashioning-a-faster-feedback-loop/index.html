<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8" />
  <title>lpil - A Faster Feedback Loop</title>
  <link rel="stylesheet" href="style.css" type="text/css" charset="utf-8">
</head>
  <body>
    <textarea id="source">
class: center, middle, inverse

# Fashioning a Faster<br>Feedback Loop

Louis Pilfold<br>
<a href="http://lpil.uk/" target="_blank">http://lpil.uk/</a><br>
<a href="https://twitter.com/louispilfold" target="_blank">@louispilfold</a>


???

Hi.

I'm Louis Pilfold and today I'd like to talk a little bit about my experience
building a faster feedback loop for Elixir development.

---
class: center, middle

Write some tests<br>
Write some code<br>
Tests pass<br>
GOTO 10<br>
<br>
<br>
<br>
<br>
<br>
<br>

???

This is my dev cycle.

I write some tests.

I write some code.

The tests let me know if my implementation has the behaviour I expect.

For me this is faster than checking in the REPL, and much faster than actually
running the app.

...

Though in reality my workflow normally looks more like this.

---
class: center, middle

Write some tests<br>
Write some code<br>
Tests **.red[FAIL]**<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>

???

I write some code. The test fails.

---
class: center, middle

Write some tests<br>
Write some code<br>
Tests **.red[FAIL]**<br>
Write some code<br>
Tests **.red[FAIL]**<br>
<br>
<br>
<br>
<br>
<br>

???

I write some code. The test fails.

And again.

---
class: center, middle

Write some tests<br>
Write some code<br>
Tests **.red[FAIL]**<br>
Write some code<br>
Tests **.red[FAIL]**<br>
Write some code<br>
Tests **.red[FAIL]**<br>
<br>
<br>
<br>

???

I write some code. The test fails.

And again.

And again.

---
class: center, middle

Write some tests<br>
Write some code<br>
Tests **.red[FAIL]**<br>
Write some code<br>
Tests **.red[FAIL]**<br>
Write some code<br>
Tests **.red[FAIL]**<br>
Write some code<br>
Tests **.red[FAIL]**<br>
...<br>

???

And so on.

Every time I edit the code I have to switch to another window to run the
tests. Now I'm both lazy and impatient, so I don't like all this switching back
and forth. I want to get the computer to do it for me.

Luckily most languages will have a tool that will automatically run your tests
for you each time you save a file.

---
class: middle

<table class="centered">
  <tr><td>Haskell</td>   <td>=&gt;</td><td>Stack</td></tr>
  <tr><td>Ruby</td>      <td>=&gt;</td><td>Guard</td></tr>
  <tr><td>Erlang</td>    <td>=&gt;</td><td>Rebar autotest</td></tr>
  <tr><td>Javascript</td><td>=&gt;</td><td>Karma, Grunt, Gulp</td></tr>
  <tr><td>&nbsp;</td>    <td>     </td><td></td></tr>
</table>

???

For example...

Haskell has Stack.

Ruby has Guard.

Erlang has Rebar autotest.

and Javascript has Karma.

But what did Elixir have?

---
class: middle

<table class="centered">
  <tr><td>Haskell</td>   <td>=&gt;</td><td>Stack</td></tr>
  <tr><td>Ruby</td>      <td>=&gt;</td><td>Guard</td></tr>
  <tr><td>Erlang</td>    <td>=&gt;</td><td>Rebar autotest</td></tr>
  <tr><td>Clojure</td>   <td>=&gt;</td><td>lein-test-refresh</td></tr>
  <tr><td>Javascript</td><td>=&gt;</td><td>Karma, Grunt, Gulp</td></tr>
  <tr><td>Elixir</td>    <td>=&gt;</td><td>???</td></tr>
</table>

???

Nothing.

When I started learning Elixir this was a problem for me, so I decided to make
this test runner one of my first Elixir projects. After much confusion about
processes, applications, OTP, and so on, I had something that worked, and I've
been using it every day since.

I'm going to walk through two implementations, and then at the end maybe you'll
have some thoughts as to how we can make it better.

If at any point you'd like me to clarify anything please call out and let me
know. I'm very happy to answer questions.

---
class: middle
<pre>
When a file is saved -&gt;
  If the file is an Elixir file -&gt;
    Recompile the project
    Run the tests
</pre>
<br>

**fs** by Vladimir Kirillov and Maxim Sokhatsky<br>
[https://github.com/synrc/fs](https://github.com/synrc/fs)<br>
[https://hex.pm/packages/fs](https://hex.pm/packages/fs)

???
This is our approach.

When a file is saved<br>
If the file is an Elixir file<br>
Recompile the project<br>
Run the tests<br>

Watching file system to detect when a file has been changed is
definately the tricky part.

Luckily Vladimir and Maxim here have already done this for us, and released the
project as a hex package called fs. It's excellent, check it out.

---
class: middle

Subscribe to fs events

```ruby
iex&gt; Application.ensure_started(:fs)
#=&gt; :ok
iex&gt; :fs.subscribe()
#=&gt; :ok
```

...save a file...

```ruby
iex&gt; flush()
#
# {#PID&lt;0.119.0&gt;, {:fs, :file_event},
#  {'/home/louis/runner/lib/runner.ex', [:modified, :closed]}}
#=&gt; :ok
```

???

fs is an application that allows a process to subscribe to file system events.

Each time a file is modified fs will send the subscriber a message
containing information about the event, like so.

In order to make use of these messages I made a GenServer that will recieve
them.

---
class: middle

```ruby
defmodule Watcher do
  use GenServer

  def start_link do
    GenServer.start_link(__MODULE__, [])
  end

  # Callbacks

  def init(_) do
    :ok = Application.ensure_started(:fs)
    :ok = :fs.subscribe()
    {:ok, []}
  end

  def handle_info({_, {:fs, :file_event}, {path, _}}, state) do
    IO.puts "file changed: #{path}"
    {:noreply, state}
  end
end
```

???

First we have the public API, which is just a start_link function which wraps
the GenServer.start_link function for the sake of having a clean API.

Then we have the GenServer callbacks.

The init callback ensures fs is started, subscribes to events, and then
starts iteration.

We also implement a clause for the handle_info function that will match the
events sent from fs. This clause just prints the path of the changed file,
which it extracts from the message.

---
class: middle

Start the Watcher GenServer

```ruby
iex> Watcher.start_link()
```

...edit a file...

```ruby
#=> "file changed: /home/louis/runner/lib/4913"
#=> "file changed: /home/louis/runner/lib/4913"
#=> "file changed: /home/louis/runner/lib/runner.ex~"
#=> "file changed: /home/louis/runner/lib/runner.ex"
#=> "file changed: /home/louis/runner/lib/runner.ex"
```

???

So if we start it in the REPL and edit a file, it works. It prints a series of
paths.

We can respond to file system events. Now it has to compile and run the
tests when it's an Elixir file that's changed.

---
class: middle

```ruby
defmodule Watcher do

  # Rest of module here...

  @pattern ~r/\.(exs|ex|erl|eex|xrl|yrl)\z/

  def handle_info({_, {:fs, :file_event}, {path, _}}, state) do
    if Regex.match?(@pattern, to_string(path) do
      Runner.run_tests()
    end
    {:noreply, state}
  end
end
```

???

Here's our updated handle_info clause in our GenServer.

First we check to see if the file has an Elixir or Erlang file extension using
a regex,

and if it matches we delegate the actual test running to a new Runner module.

So how does the run_tests function run the tests?

---
class: middle, center, inverse, large

# Ports

???

Has anyone used Erlang Ports?

Ports are a way of running commands in the shell. Anything that is printed by
the shell command will be sent back to the process as a message.

---
```ruby
defmodule Runner do
  @args ~w(stream binary exit_status use_stdio)a
  def run_tests do
    {:spawn, "mix test"}
    |&gt; Port.open(@args)
    |&gt; results_loop
    :ok
  end

  defp results_loop(port) do
    receive do
      {^port, {:data, data}} -&gt;
        IO.write(data)
        results_loop(port)
      {^port, {:exit_status, status}} -&gt;
        status
    end
  end
end
```

???

Here's our function.
It creates a port that runs the command "mix test", and then enters a receive
loop.

When the message contains IO data, we print it and loop again. When it contains
an exit status the tests have finished running, so we return back to the
GenServer and await the next event.

If you use this as it is, you will find that the tests will be run multiple
times when you save one file.

Even worse, if you edit files while the tests are running those will also add
more test runs to the queue, and you'll end up with tests running continuously
whether you want them to to or not.

This happens because there are actually many events occuring when a file is
saved, and our Watcher faithfully works through all the events, running the
tests for each one.

---

```ruby
defmodule Watcher do

  # Rest of module here...

  def handle_info({_, {:fs, :file_event}, {path, _}}, state) do
    if Regex.match?(@pattern, to_string(path) do
      Runner.run_tests()
*     discard_messages() # Empty inbox after a test run
    end
    {:noreply, state}
  end

  def discard_messages do
    receive do
      _       -&gt; discard_messages()
      after 0 -&gt; :ok
    end
  end
end
```
???

My solution here was to empty the process inbox of any messages immediately
after running the tests.

To do so we simply enter a receive loop that does nothing for all messages.

This little after 0 trick allows us to stop iteration if there are no
messages left, rather than looping forever.

It's saying "if we have to wait at all for another message, time out and break
out of the recieve block.

---
class: middle

```plain
iex&gt; Watcher.start_link()
:ok
iex&gt;
......................................................
................

Finished in 0.3 seconds (0.3s on load, 0.04s on tests)
74 tests, 0 failures, 4 skipped

Randomized with seed 387360
```

???

And that's pretty much how this test runner has worked for the last year and a
half. It's OK, it works. But what can be improved here?

For starters this doesn't work on Windows as with ports we're relying on the
Unix shell.

It's also not as fast as it could be. Each time we run the tests we launch a
new instance of the virtual machine, and then it has to load the bytecode,
start the applications, and so on.

Wouldn't it be great if we could avoid the shell altogether and just run the
tests inside the existing virtual machine?

How about we compile and run the tests with the virtual machine that's already
running?

---
```plain
$ MIX_ENV=test iex -S mix
```

```ruby
iex&gt; Mix.Task.run("test")
# ......................................................
# ................
#
# Finished in 0.3 seconds (0.3s on load, 0.04s on tests)
# 74 tests, 0 failures, 4 skipped
#
# Randomized with seed 387360
[Function<2.127709695/1 in Mix.Tasks.Test.run/1>]
```

???

If we want to run the tests like this we need to make sure we start
the VM in the test environment, otherwise they will throw an exception.

This is the Mix.Task.run function, which allows us to invoke mix tasks.

If we call it with the string "test" the tests run. Simple.

---

```plain
$ MIX_ENV=test iex -S mix
```

```ruby
iex&gt; Mix.Task.run("test")
# ......................................................
# ................
#
# Finished in 0.3 seconds (0.3s on load, 0.04s on tests)
# 74 tests, 0 failures, 4 skipped
#
# Randomized with seed 387360
[Function<2.127709695/1 in Mix.Tasks.Test.run/1>]

iex&gt; Mix.Task.run("test")
```

???

What happens it we call it again?

---

```plain
$ MIX_ENV=test iex -S mix
```

```ruby
iex&gt; Mix.Task.run("test")
# ......................................................
# ................
#
# Finished in 0.3 seconds (0.3s on load, 0.04s on tests)
# 74 tests, 0 failures, 4 skipped
#
# Randomized with seed 387360
[Function<2.127709695/1 in Mix.Tasks.Test.run/1>]

iex&gt; Mix.Task.run("test")
:noop
```

???

Nothing. It doesn't run the tests.

This is because mix maintains some internal state, and doesn't run tasks if
they have already been invoked already.

This is useful as we can build dependancy trees out of mix tasks, and mix will
work out how to run them sequentially without repeating itself.

For example, the test command depends upon the compile command, as does the
docs command. If you run both test and docs it'll run compile once for the test
command, but not again for the docs command as that requirement has already
been met.

This is great for build tasks, but less good for our use case. Luckily mix
gives us a way to re-enable tasks we want to run more than once.

---
class: middle

```ruby
defmodule Runner do
  def run_tests do
    reenable_test_tasks()
    Mix.Task.run("test")
  end

  defp reenable_test_tasks do
    Mix.Task.reenable("loadpaths")
    Mix.Task.reenable("deps.loadpaths")
    Mix.Task.reenable("test")
  end
end
```

???

Here's our new Runner module. It reenables the test task and the two dependancy
tasks, and then runs the test task.

---

```ruby
iex&gt; Runner.run_tests()
# ......................................................
# ................
#
# Finished in 0.3 seconds (0.3s on load, 0.04s on tests)
# 74 tests, 0 failures, 4 skipped
#
# Randomized with seed 387360
[Function<2.127709695/1 in Mix.Tasks.Test.run/1>]

iex&gt; Runner.run_tests()
# ......................................................
# ................
#
# Finished in 0.3 seconds (0.3s on load, 0.04s on tests)
# 74 tests, 0 failures, 4 skipped
#
# Randomized with seed 792311
[Function<2.843757605/1 in Mix.Tasks.Test.run/1>,
  Function<2.127709695/1 in Mix.Tasks.Test.run/1>]
```
???

We can now run the tests more then once, but there's a problem. We're not
recompiling and reloading the code, so our tests are locked to the codebase
when we started the VM. We need to force recompilation in order to get for our
edits to register.

---
class: middle

```ruby
defmodule Runner do
  def run_tests do
*   recompile_project()
    reenable_test_tasks()
    Mix.Task.run("test")
  end

  @compile_tasks ["compile", "compile.all",
    "compile.protocols", "compile.app", "compile.elixir",
    "compile.erlang", "compile.yecc", "compile.leex",
    "loadpaths", "deps.loadpaths"]

  defp recompile_project do
    Enum.each(@compile_tasks, &amp;Mix.Task.reenable/1)
    Mix.Task.run("compile")
  end

  # Other code here...
end
```

???

Reenabling compilation looks a lot like reenabling test running.

There's a new function called recompile_project, which calls
Mix.Task.reenable on some dependancy tasks, and then runs the compile task.

Changes to our application code are now picked up each time we edit a file, but
changes to our test code are not. Why is this?

The compile task ignores the test directory entirely, instead is it the test
task that loads the test module. Unlike the compile task it won't check to see
if there is a newer version of the code as it doesn't expect any test code to
be loaded before being run.

We have to make Elixir forget that it's already seen the test files.

---
class: middle

```ruby
iex&gt; Code.loaded_files()
["/home/louis/runner/mix.exs",
 "/home/louis/runner/test/test_helper.exs",
 "/usr/local/bin/mix",
 #... and more...
]
```

???

If you rummage around inside the Elixir source code you'll find there's an
Erlang process called the "elixir_code_server" that keeps track of paths to
files that have already been loaded. Any file that is already known will not be
loaded by the test task.

---
class: middle

```ruby
defmodule Runner do
  def run_tests do
*   unload_test_files()
    recompile_project()
    reenable_test_tasks()
    Mix.Task.run("test")
  end

  defp unload_test_files do
    ["test"]
    |&gt; Mix.Utils.extract_files("*")
    |&gt; Enum.map(&amp;Path.expand/1)
    |&gt; Code.unload_files
  end

  # Other code here...
end
```
???

The Code module exposes a few functions that we can use to interact with the elixir_code_server, including one called unload_files. This function takes a list of absolute paths to files, and unloads them.

Note this only unloads the files, the modules are managed by the VM and another
process called the erlang_code_server, so they stay available.

Here I've changed the run_tests function to build a list of test files, and
then pass them to the unload_files function.

---
```plain
$ MIX_ENV=test iex -S mix
```

```plain
iex&gt; Runner.run_tests()
......................................

Finished in 0.6 seconds (0.1s on load, 0.5s on tests)
38 tests, 0 failures

iex&gt; Runner.run_tests()
```

???

The tests still work it we run it a first time.

And if we run it a second time...


---
```plain
$ MIX_ENV=test iex -S mix
```

```plain
iex&gt; Runner.run_tests()
......................................

Finished in 0.6 seconds (0.1s on load, 0.5s on tests)
38 tests, 0 failures

iex&gt; Runner.run_tests()
test/calc_test.exs:1: warning: redefining module FooTest
test/addition_test.exs:1: warning: redefining module AddtionTest
test/multiply_test.exs:1: warning: redefining module MultiplyTest
test/division_test.exs:1: warning: redefining module DivisionTest
test/subtraction_test.exs:1: warning: redefining module SubtractionTest
test/prime_test.exs:1: warning: redefining module PrimeTest
test/parser_test.exs:1: warning: redefining module ParserTest
......................................

Finished in 0.6 seconds (0.1s on load, 0.5s on tests)
38 tests, 0 failures
```

???

Well it sort of works- our test code is reloaded on each run now. However,
because the test **modules** are already in memory we get these nasty warnings
when as they are redefined.

This is only a tiny project here, and it's already pretty noisy. Imagine if you
had tens or hundreds of modules, each emitting a warning like this.

What can we do about this?

---
class: middle
```erlang
check_module_availability(Line, File, Module) -&gt;
  case elixir_compiler:get_opt(ignore_module_conflict) of
    false -&gt;
      case code:ensure_loaded(Module) of
        {module, _} -&gt;
          elixir_errors:form_warn([{line, Line}],
            File, ?MODULE, {module_defined, Module});
        {error, _}  -&gt;
          ok
      end;
    true -&gt;
      ok
  end.
```
???

Inside the Elixir compiler there is a Erlang module that confusingly enough is
called elixir_module. It contains a function called format_error, one clause of
which builds our warning message. This clause is called from a function called
check_module_availability, in the same module.

Here we can see it checks if the module is loaded using ensure_loaded function
in the Erlang code module, and calls the warning function if is loaded.

However, it doesn't do this check at all if elixir compiler
ignore_module_conflict has been set.

---
class: middle
```ruby
defmodule Runner do
  def run_tests do
*   Code.compiler_options(ignore_module_conflict: true)
    unload_test_files()
    recompile_project()
    reenable_test_tasks()
    Mix.Task.run("test")
  end

  # Other code here...
end
```

???

It turns out that the Code module gives us an easy way to enable this option at
runtime. We just pass ignore_module_conflict: true to the compiler_options
function.

---
class: middle
```ruby
defmodule Runner do
  def run_tests do
    Code.compiler_options(ignore_module_conflict: true)
    unload_test_files()
    recompile_project()
    reenable_test_tasks()
    Mix.Task.run("test")
*   :elixir_config.put(:at_exit, [])
  end

  # Other code here...
end
```

???

If you run the tests normally and tests fail, Elixir will exit with a non-zero
exit code. It acheives this by registering an on_exit callback function. To
avoid leaking a little bit of memory with each run we clear this callback after
each run like so.

---
class: inverse, middle, center

# Demo


    </textarea>
    <script src="../vendor/remark-0.11.0.min.js"></script>
    <script>
var slideshow = remark.create({
  highlightStyle: "monokai",
  highlightLanguage: "remark",
  highlightLines: true,
});
    </script>
  </body>
</html>
