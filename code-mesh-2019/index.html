<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>lpil - Gleam: Lean BEAM typing machine</title>
  <link rel="stylesheet" href="./style.css" type="text/css" charset="utf-8">
</head>
  <body>
    <textarea id="source">
class: middle center slide-bold
<img style="width: 65%" src="img/lucy-charcoal-3.svg">

---
class: middle,center
## Hi, I'm Louis!

https://lpil.uk/talk-slides/code-mesh-2019

???

Hello everyone! Welcome!

I'm Louis! I'm an Erlang person and I usually talk at Erlang events so I
wasn't sure what kind of audience I'd attract today.

I've tried to write this talk so that you don't need any Erlang or ML
experience, but if at any point what I'm saying doesn't make sense to you
please wave your hand or ask a question and I'll try and clear things up.

Hopefully everyone can see the slides OK, but just in case you can find a copy
at this URL.

Let's get started!

---
class: slide-dark middle center
<img style="width: 75%; padding-right: 45px" src="img/gleam-pink.svg">

???

I'm here today to talk about Gleam, which is a new statically typed
programming language for the Erlang virtual machine that I've been working on
for the last 2 years or so.

Gleam draws inspiration from both BEAM languages such as Elixir and Erlang,
and ML languages such as Haskell and Elm.

In this talk I'm going to take a look at these two language families and see why
I think they're fantastic to work with.

We'll take a look at some of their strengths, some of their weaknesses, and
how Gleam, this new language, attempts to bring together some of the best
traits of both.

Lastly I want to share a little of where Gleam is going next, hopefully with
some time for questions at the end.


---
class: slide-bold middle center
<img style="width: 45%; position: absolute; top: 5%; left: 27%" src="img/lucy-charcoal-6.svg">
<br>
<br>
<br>
<br>
<br>
# Why Erlang?
???

Question #1: Why Erlang?

One of Gleam's greatest strengths is that it compiles to Erlang and as such
can take advantage of all the wonderful things that Erlang has to offer.

This begs the question: what's so special about Erlang?


---
class: middle
<img class="color-adjust center-element" src="img/the-beam.png">
???

A large part of the answer to that question is the BEAM, the Erlang virtual
machine.

Erlang is slightly unusual for an older functional programming language in
that it originated largely from industry rather than academia. Back in the 80s
the telephony company Ericsson were looking for the ideal language for writing
telephone switch firmware in, and from this real-world need Erlang was born.

---
class: middle
<img class="color-adjust center-element" style="" src="img/telephone-switch-one-call.png">
???

A telephone switch is a piece of hardware connects phone calls.

When a person dials a number of their phone, their local switch identifies
where the call is attempting to connect to and creates a complete circuit
between the caller and the receiver.

Back when the telephone was first invented this would have been the job of a
person sitting at a switch-board, physically connecting different circuits
with bits of wire.

After that came automatic mechanical switches that didn't require a person to
make the connection, and later digital switches, which would create virtual
circuits within software.

It was these digital switches for which Erlang was created in the 80s.

In order to meet the unusual requirements of the telephony hardware
Erlang and the BEAM developed some rather novel features.

---
class: middle
<img class="color-adjust center-element" style="" src="img/telephone-switch.png">
???

For a telephone switch to be useful it needs to be able to support multiple
phone calls at the same time. If you had to wait for your neighbour to get off
the phone before you could make a call I suspect telephones probably wouldn't
have caught on.

Because of this Erlang had to have great concurrency features so that one
switch could handle many calls at once.

Any program written in Erlang needed to be able to trivially perform a great
number of tasks at the same time.

This was such an important feature they ended up naming the language after it.
As well as being a programming language an Erlang is a unit of concurrency, it
measures seconds per second.

A telephone switch that can hold 100 simultaneous calls can support a load of
100 Erlangs.

So how does the BEAM scale when it comes to concurrency? We can look at some
benchmarks of real-world systems.


---
## 2 million ejabberd connections
<img class="center-element" style="max-width: 70%" src="img/ejabberd.png">
<cite>
https://blog.process-one.net/ejabberd-massive-scalability-1node-2-million-concurrent-users/
</cite>
???

ejabberd is a websocket based chat server, a fork of which powers WhatsApp,
the popular chat app owned by Facebook. In their benchmarks the ejabberd team
recorded 2 million active connections to a single server, which is quite a
feat.

Another interesting fact is that WhatsApp was capable of running their
ejabberd based chat platform with 900 million users with only 50 engineers.


---
## 2 million Phoenix connections
<img class="center-element" style="max-width: 85%" src="img/phoenix.png">
<cite>
https://phoenixframework.org/blog/the-road-to-2-million-websocket-connections
</cite>
???

Phoenix Channels is a websocket based pubsub system with sophisticated
presence features.

In their benchmarks the Phoenix team also scaled to 2 million active
connections on a single machine, and even with this load they were able to
publish events to all the connected clients in under a second.

A common feature of both this and the ejabberd benchmark is that the limiting
factor was reported as being not the BEAM itself, but the underlying network
hardware and the Linux networking stack.

Turns out it is somewhat difficult to open and use 2 million TCP sockets on
your average Linux server in a public cloud.


---
## 20 million Erlang threads
<br>
<br>
<img class="center-element" style="" src="img/ericsson.png">
<br>
<br>
<br>
<cite>
https://groups.google.com/forum/#!original/comp.lang.functional/5kldn1QJ73c/T3py-yqmtzMJ
</cite>

???

Lastly, in a more contrived benchmark, the Erlang team at Ericsson tested to
see how many threads they could create in a single Erlang program. On a
computer with 16GB of RAM they found they could create 20 million threads
without problem.

During this benchmark it took an average it took 5 nano-seconds to create a
thread, and 6 nano-seconds for any of these threads to respond to a message
sent to it.

This benchmark was undertaken back in 2005 so by today's standards this
was on a somewhat underpowered machine, we could likely beat this with Erlang
today.


---
class: middle
<img class="color-adjust center-element" style="" src="img/telephone-switch.png">
???

When it comes to concurrency the BEAM can definitely scale, but it's not good
enough to mearly be possible; Ericsson needed this to be relatively easy so
their firmware developers could be as productive as possible.

Asynchronous programming is notoriously difficult, especially if you're
working with tools like locks, callbacks, and shared mutable state, so the
creators of Erlang went down a different route.

Rather than having a small number of threads each handling a large number of
concurrent tasks, in the Erlang world we use a great number of threads, but
each thread only has 1 task to perform.


---
class: middle
<img class="color-adjust center-element" style="" src="img/telephone-switches.png">
???

If each thread only has to do one thing it can be written in a sequential
fashion. The programmer doesn't have to write any asynchronous code within the
single thread.

To paraphrase the late Joe Armstrong, creator of Erlang:

It's difficult to write a web server capable handling 2 million sessions.

However, it is much easier to a write web server capable of handling a single
session, and to then run 2 million copies of it.



---
class: minimal-padding
## Multi-threaded
<img class="color-adjust center-element" style="" src="img/multi-threaded.png">
???

To support this level of concurrency Erlang threads are not implemented as
operating systems threads, instead they are lightweight threads called
Processes, running on their own scheduler within the BEAM.

Back in the late 80s computer processors only had a single core, so while
Erlang programs were highly concurrent they were still single threaded.

When processors with multiple cores started to appear the BEAM was upgraded to
schedule Erlang processes across all available cores, making full use of all
processing power available.

Overnight all Erlang programs became multi-threaded programs, and now writing a
multi-threaded program in Erlang is no more difficult than writing a
single-threaded one.

Sadly the processes in these telephony switches couldn't be completely
isolated from each other, there's always going to need to be some
communication and synchronisation between threads in any program.


---
## Messages
<br>
<img class="color-adjust center-element" style="max-width: 90%" src="img/messages.png">
???

Rather than using shared state communicate with each other Erlang processes
communicate by sending messages to each other.

What's more processes within a telephone switch don't need to just talk to
processes within the same switch, they also need to communicate with many
other devices in the network, as calls are routed through various pieces of
telephone hardware to get to their destination.

To facilitate cross-network communication the BEAM has distributed computing
features built in. When sending a message it doesn't matter if
- the processes are running on the same instance of the BEAM,
- different instances of the BEAM on the same computer,
- or even two completely different computers connected by a network:

The processes can still send messages to each other.

Distributed computing is built into the BEAM, a typical BEAM program written
in Erlang or Elixir can be turned into distributed program that runs on a
cluster of networked computers with minimal effort.


---
## Garbage collection
<img class="color-adjust center-element" src="img/garbage-collection.png">
???

Ericsson didn't want their programmers to have to deal with the error prone
business of manual memory management, so the BEAM implements garbage
collection.

This however posed a problem. Many runtimes will pause all computation in
order to perform garbage collection, but here that's not an option. The switch
can't let all calls hang for a second while it sorts out the memory, it needs
to continue to operate continuously without interruption.

So instead of performing garbage collection on the entire program the BEAM
performs it on a per process basis. Rather than stopping everything only
individual processes that are due a clean-up will be paused, giving Erlang
programs predictable low-latency.


---
## Fault tolerance
<img class="color-adjust center-element" src="img/isolation.png">
???

And perhaps most excitingly, Erlang processes act as error bulkheads, meaning
that when something does go wrong and your code crashes the problem is
contained to the smallest possible sub-system and will not impact any other
work being undertaken by the program.

An Erlang program that takes advantage of this property can self heal by
restarting the process and trying again, hopefully succeeding now that any
corrupt state has been shed.

In this way the BEAM is much like Kubernetes, the popular container
orchestrator from Google.

What makes the BEAM different from Kubernetes is that this state shedding can
happen at a much more fine grained level- we won't lose the state of the
entire program and all the requests being handled by it, instead just the
single process that had the problem.

You could image the relationship between the BEAM and Kubernetes being similar
to the relationship between Kubernetes and datacenter failover. They're
similar, but they operate at different levels of abstraction.


---
## Getting less niche
<img class="color-adjust center-element" style="" src="img/telephones-to-computers.png">
???

The BEAM was created with the problem of telephony in mind, but it turns out
that what was once quite a niche set of problems is actually quite commonplace
today.

Concurrency, parallelism, distribution, consistent low latency, and fault tolerance:
these are characteristics we want in networked services today.

The BEAM has almost by chance has become an excellent platform for building
web applications, databases, message brokers, or many of these other things
that web developers deal with on a daily basis.


---
## Why a new language?
<br>
<img class="center-element" src="img/beam-languages.png">
???

So now we've seen a little of why I think the BEAM is a wonderful platform,
but I've not answer the question of why make a new language at all.

We already have several fantastic languages on the BEAM such as Erlang,
Elixir, and LFE. Why spend all this time creating Gleam when we could use one
of these?

To answer this question I'd like to take a closer look at the BEAM's self
healing properties and how that impacts us as developers and operators of
software.

---
class: minimal-padding middle
<img class="color-adjust" src="img/cycle-1.png">
???

It's a normal day at work and I've got a change to make to an application.
Perhaps I'm adding a feature, maybe we're removing a bug, it doesn't matter,
I'm making some sort of change.

I spend some time editing the code, making my changes.

---
class: minimal-padding middle
<img class="color-adjust" src="img/cycle-2.png">
???

Once satisfied run the compiler to build the application, which completes
successfully, reporting no problems.

---
class: minimal-padding middle
<img class="color-adjust" src="img/cycle-3.png">
???

After that I run the unit tests on my laptop to ensure I've not broken
anything, and then push my changes to GitHub.

---
class: minimal-padding middle
<img class="color-adjust" src="img/cycle-4.png">
???

Once uploaded the code triggers a build on the CI server. It runs all the unit
and integration tests, and runs some linters to try and spot any mistakes.

---
class: minimal-padding middle
<img class="color-adjust" src="img/cycle-5.png">
???

If all those checks pass then it deploys the new application version to a
staging environment.

---
class: minimal-padding middle
<img class="color-adjust" src="img/cycle-6.png">
???

On the staging environment I manually test the application and demo the new
behaviour to stakeholders who give the green light to continue.

---
class: minimal-padding middle
<img class="color-adjust" src="img/cycle-7.png">
???

Meanwhile, on GitHub the code is reviewed by some of the other programmers on
my team, as they may have some context or insights that I do not.

---
class: minimal-padding middle
<img class="color-adjust" src="img/cycle-8.png">
???

Happy with my changes they approve it and the code is merged into
master, triggering another CI build.

---
class: minimal-padding middle
<img class="color-adjust" src="img/cycle-9.png">
???


All the tests and linters are run again to ensure no problems were introduced
during the merging process.

---
class: minimal-padding middle
<img class="color-adjust" src="img/cycle.png">
???

And lastly, once the tests have passed again the code is deployed to
production, and released to our users. Satisfied with a job well done, I go for
lunch.

But then! Disaster strikes! Users are reporting that the application no longer
works as intended. Right at the very beginning when I was editing the code I
made a mistake and introduced a bug.

Each one of these steps has failed to detect the problem and now the bug has
snuck into production. Luckily the application is written in Erlang so the
impact of the problem has been minimised, but I still need to fix the problem
as a matter of urgency.

---
class: center middle
<img class="color-adjust" src="img/time.png">
???

In this instance the problem was discovered just a few hours after I made the
mistake, so the change is still fresh in my mind and it's not too difficult to
correct it, but that's not always the case.

Depending on the culture of the company I'm working at it might take days or
weeks for a change to be deployed to production, or it might have taken longer
for the users to discover the problem.

Worse case scenario it has been months or years and the writer of the bug has
long since left the company, leaving me to try and fix code I've never seen
before.

---
class: center middle
<img class="color-adjust" src="img/science.png">
???

The larger the gap between the mistake being made and the problem being
detected the more difficult it will be to fix.

Of course this isn't the only factor in the difficulty, but it is an important
multiplier.

Erlang gives us powerful tools to tolerate mistakes and debug them, but they
largely only help us once the code is in production, and that time cost and
loss of familiarity is far from optimal.

---
class: minimal-padding middle center
<img class="color-adjust" src="img/bug-detected.png">
???

What I really want is to for problems to be detected here, immediately after the
mistake was made.

I want that feedback loop to be as fast as possible so we can spend less time
doing exploratory work (such as debugging) and more time iterating (actually
providing business value).

---
class: minimal-padding center middle
<img class="color-adjust" style="padding-bottom: 40px" src="img/ml-family.png">
???

Gleam aims to provide that fast and safe feedback loop by introducing a type
system inspired by those found in the ML family of languages.

Why these languages? Because I believe they are currently the languages that
do best at providing this rapid feedback loop.

Let's look at some examples:

---
## Reason

<img class="center-element" style="max-width: 60%" src="img/messenger.png">

> Messenger used to receive bugs reports on a daily basis; since the
> introduction of Reason, there have been a total of 10 bugs (that's during
> the whole year, not per week)!

> Refactoring speed went from days to hours to dozens of minutes.

<cite>
https://reasonml.github.io/blog/2017/09/08/messenger-50-reason.html
</cite>

???

Messenger is Facebook's web chat program. It has 1.3 billion monthly users.

Back in 2016 they started converting the web client from Javascript to a
dialect of OCaml called Reason. A year later 50% of their code was written in
Reason and they had this to say:

**QUOTE**

Quite an impressive statement!


---
## Elm
<img class="center-element" style="max-width: 70%" src="img/noredink.png">

> After 2 years and 200,000 lines of production Elm code, we got our first
> production runtime exception.

> In that period, our legacy JS code has crashed a mere 60,000 times.

<cite>
Richard Feldman -
https://twitter.com/rtfeldman/status/961051166783213570
</cite>

???

NoRedInk are a company in the United States that provide education software.

Back in 2016 they started adding Elm code to their Coffeescript web
application with great success. In 2018 one of their engineers, Richard
Feldman, posted this tweet:

**QUOTE**

This is not to say the engineers at NoRedInk and Facebook are without error,
they make as many mistakes as you or I.

The key takeaway here is that they are discovering and fixing their mistakes
before they get to production, or at least the ones that cause runtime errors.


---
## Purescript
<img class="center-element" style="max-width: 70%; padding-bottom: 40px" src="img/lumi.png">

> [Iâ€™ve had] such a positive experience, with little mental overhead, and
> total trust in the compiler. I implemented an entire page with a list of
> data, filters, search, and pagination which worked first time.

<cite>
Brandon Martin -
https://www.lumi.dev/blog/purescript-and-haskell-at-lumi
</cite>

???

Lumi are a company that provide custom eco-friendly branded packaging for
online stores.

In 2018 they started converting their Javascript frontend into a Purescript
frontend. After a few months of Purescript in anger engineer Brandon Martin
had this to say:

**QUOTE**

What I like about this is the feeling of trust in the compiler, that it is
something that can be relied on.

With Gleam I want to create the experience in the BEAM ecosystem of the
compiler being like a pair programming partner, there to help by catching
mistakes and providing additional insight.

---
class: slide-bold middle center
<img style="width: 45%; position: absolute; top: 5%; left: 27%" src="img/lucy-charcoal-6.svg">
<br>
<br>
<br>
<br>
<br>
# Error detection
???

How do they achieve this? By having a compiler capable of analysing the code
for inconsistencies, and providing precise feedback to the programmer,
detailing every place where a problem may arise.

Once the programmer has this ability to discover all the possible problems in
the application the way they approach writing code can change.


---
<br>
```rust
fn get_user_name(user) {
  let User(name: name) = user
  name
}
```
<center><h3>â‡©â‡©â‡© becomes â‡©â‡©â‡©</h3><center>
```rust
fn get_user_name(user) {
  let User(name: name) = user
  case name {
    "" -> Null
    _ -> Just(name)
  }
}
```
???

First the programmer makes an edit, informing the compiler of the change they
wish to make. For example, perhaps a function has been changed to sometimes
return a null value under certain circumstances.

In languages like Erlang without this static analysis it is up to the
programmer to now find all the the places in the codebase that need to be
updated to correctly handle this new nullable value.

In Erlang they would possibly do this using a mix of already existing unit
tests and their familiarly with the codebase. That would aid their manual
search.

---
<br>
<img class="center-element" style="" src="img/nullable-error.png">
???

In Gleam and ML languages the compiler outputs a TODO list of inconsistencies,
and the programmer goes through the list, fixing them one by one.

No need for doing discovery work- just state the change to be made, and the
compiler then shows you how to integrate that change.

As I said before you can achieve the same with a robust set of unit tests, but
I think this system has a few advantages.

We don't have to write the tests, the compiler does this checking for us. This
static analysis can be thought of as basic full test coverage for free. It
even covers code that is hard to test, such as code that performs IO.

Secondly this static analysis is fast. A large codebase can be checked in
seconds or fractions of a second, while the tests may take minutes.

Thirdly the compiler can provide the precise location of the cause of the
error, while tests can only ever give you the location of a resulting symptom.
Once a test presents an error it is up to the programmer to determine if the
problem originated there or somewhere else entirely.


---
class: slide-bold middle center
<img style="width: 50%; position: absolute; top: 5%; left: 25%" src="img/lucy-charcoal-5.svg">
<br>
<br>
<br>
<br>
<br>
## Do we need fault tolerance?

???

It might seem like **with** this ML style error detection the BEAM's runtime
fault tolerance and error handling features are somewhat redunant, but I think
they can complement each other quite nicely.

The error detection means that we are aware of all the places where there can
be a problem, and then we can make an explicit decision about how we want to
handle it.

And because the decision of how to handle an error is now explicit the
compiler can tell if a crash is intentional, or if a mistake has been made.

This isn't very clear, so let's look at some examples.

---
## Programmer mistake
```rust
fn main() {
  list.reverse("hello") // Error! Not a list
}
```
<center><h3>â‡©â‡©â‡© use the correct function â‡©â‡©â‡©</h3><center>
```rust
fn main() {
  string.reverse("hello") // That's better :)
}
```
???

Imagine a problem caused by a mistake on my part as a programmer

For example, I'm trying to reverse a binary string, but I'm using a function
that reverses lists.

In this case once the error has been highlighted to me by the compiler I
realise I've made a mistake, and then I'm going to fix the bug.

Erlang's fault tolerance wasn't useful here. If a trivial mistake like this
has been made I want to find it and I want to fix it.


---
## Incorrect user input
```rust
fn handle(request) {
  let input = decode_json_body(request)
  save_record(input) // Error! JSON could be invalid
}
```
<center><h3>â‡©â‡©â‡© handle invalid input â‡©â‡©â‡©</h3><center>
```rust
fn handle(request) {
  let result = decode_json_body(request)
  case result {
    Ok(input) -> save_record(input)
    Error(reason) -> unprocessable_entity(reason)
  }
}
```
???

Another situation in which errors may arise is when dealing with user input.

Here we have a handler function from a web application; it takes a request
data structure and returns an appropriate response.

As part of this it reads some data from the request body, and that data has
been in encoded in the JSON format.

The problem here is that the request body might not contain valid JSON, we
can't rely on always getting the correct input from the outside world.

Once this problem has been highlighted to us by the static analysis the most
practical thing to do is to check whether the JSON is valid or not. If it
isn't we can then return an error message to the user, informing them that
there is something wrong with their JSON encoding.

If we can pass an error back up the chain to the user then that's often the
best thing to do.

Erlang's fault tolerance wasn't useful here either.

---
## Background processing
```rust
fn process_video(id) {
  let metadata = lookup_metadata(id)
  create_thumbnails(metadata)
  transcode_video(metadata)
  "done!"
}
```
???

I used to work at a start up that did video transcoding. We had a lot of jobs
that ran in the background and as a result they didn't immediately have a user
attached to them.

One of the jobs looked like this:
- first it looked up some metadata from the database
- then it created some thumbnail images
- lastly it transcoded a video into some other format

Each one of these steps is expected to always succeed according to our
business logic, but because of the nature of the universe there is very real
chance these things could fail.

- A faulty hard drive could corrupt a video file,
- the unreliable network could cause a database lookup to fail.
- There could be a bug in the third party transcoder software that causes it
  to crash.


---
## Defensive programming
```rust
fn process_video(id) {
  case lookup_metadata(id) {
    Ok(metadata) ->
      case create_thumbnails(metadata) {
        Ok(result) ->
          case transcode_video(metadata) {
            Ok(_) -> "done!"
            Error(transcoder_error) -> ???
          }
        Error(transcoder_error) -> ???
      }
    Error(database_error) -> ???
  }
}
```
???

The ML style error detection forces the programmer to acknowledge these
potential problems, and we end up this verbose nested code.

After each step the programmer has to check to see whether if failed, and then
do *something* with the error if it is present.

This code is much less clear than the previous version. It's harder to tell
what the business logic is here as it is obscured by error handling.


---
## Defensive programming
```rust
fn process_video(id) {
  let result = id
    |> lookup_metadata
    |> result.then(fn(metadata) {
      metadata
      |> create_thumbnails
      |> result.map(fn(_) { metadata })
    })
    |> result.then(transcode_video)
  case result {
    Ok(_) -> "done!"
    Error(e) -> ??? // What do we do with the error?
  }
}
```
???

It's possible to rewrite the job using some higher order functions that
extract some of the conditional logic.

This removes some of the nesting but now the reader needs to be familiar with
all of the extra functions used to understand the code, and the code is still
much more complicated than what we started with.

To make matters worse it's not even clear what we should do with the error
once we have it. There's no user to return it to. Perhaps we need to create
some kind of error logging system.

At this point I suspect that any Erlang people in the audience are itching to
jump up and shout there is another way to approach this. There is an
alternative to this defensive programming.


---
## Offensive programming
```rust
fn process_video(id) {
  assert Ok(metadata) = lookup_metadata(id)
  assert Ok(_) = create_thumbnails(metadata)
  assert Ok(_) = transcode_video(metadata)
  "done!"
}
```
???

And that alternative is offensive programming.

If your business logic says that something should never fail, and you have no
way of reasonably handling the failure, don't check for the error.

Instead make an assertion saying "in order to continue no error must
happened", and if there was an error we crash the process as there's no
sensible way to continue *at the process level*.

And now the BEAM's fault tolerant properties come into play- the crash is
logged and reported, and the process can be restarted as required. The rest of
the program continues running without problem.

As the Erlang saying goes, let it crash.

---
class: slide-bold middle center
<h1 style="font-size: 5em">Let it crash</h1>
## (if you're sure)
???

The ML style type system helps us find all places where error can happen,
and then we can categorised them into two different groups.

The errors that are expected within our domain, such as invalid user input,
we can deal with locally with conditional logic.

The errors which are exceptional and outside out domain, such as data
corruption, can be handled non-locally using processes and the BEAM.

If an error is truely unexpected it shouldn't get in the way of your business
logic, and you shouldn't have to write extra code for your program to tolerate
it.


---
class: slide-bold middle
<img style="width: 45%; position: absolute; top: 5%; left: 30%" src="img/lucy-charcoal-2.svg">
<br>
<br>
<br>
<br>
<br>
# What's next for Gleam?
???

So hopefully now you can see a little of the value of bringing together these
two language families, and what is the appeal of Gleam.

Now let's take a bit more of a mundane look at what's coming next.

Gleam as a language, a compiler, and a standard library are ready to be used
in people's projects, however we're missing many of the niceties that are
required for programmers to be productive.

My current focus is to supply everything that is required for people to be
productive with Gleam in order to build the community, and once that is done
we can look at more exciting language enhancements.

---
## Editor integration

<img class="center-element" style="" src="img/editors.png">

???

Having good development tooling is important for productivity.

We want the experience of writing Gleam code to be as slick and enjoyable as
possible, no matter what the editor the programmer is using. To achieve this
Gleam will implement Microsoft's Language Server Protocol.

Once implemented Gleam programmers will have high quality IDE like features no
matter what text editor they are using.

And what's more thanks to Gleam's type system and static analysis this tooling
will be able to provide much richer information to the programmer than is
possible with other BEAM languages.

---
## Documentation
<img class="center-element" alt="documentation" style="" src="img/documentation.png">

???

Another part of the developer experience puzzle is documentation.

I don't know if anyone here has written a program in Gleam but right now it's
not as easy as it ought to be.

Unless you want to read the source code of any libraries you're using there's
no way to learn what modules and functions are available.

---
class: splash-image
<img src="img/hexdocs.png">
???

Meanwhile Elixir has the beautiful, searchable, mobile friendly documentation
generated from the code itself, hosted on hexdocs (a unified website for BEAM
documentation), and linked directly to the BEAM package management system.

In Elixir it's easy to find the documentation you need, whether it's online,
in your editor, or on the command line, or even within your program itself,
and we intend for this to be the case for Gleam too.


---
class: center
## Exercism
<img class="center-element" style="max-width: 70%" src="img/exercism.png">

https://exercism.io

???

Who's familiar with Exercism?

Exercism is a fantastic place for people to learn new programming languages
and to practice their coding skills.

---
class: middle

<img class="center-element" src="img/exercism-learn.png">
???

How does it work? A programmer picks a language they want to practice and
Exercism gives them an exercise to complete.

Each exercise has instructions, some skeleton code to fill in, and a full set
of unit tests to make pass.


---
class: middle

<img class="center-element" style="padding-top: 69px" src="img/exercism-chat.png">


???

Once the programmer has completed their solution they can to submit it back to
Exercism, where they get getting friendly and constructive feedback from track
mentors and other students.

They can also view solutions from other people and learn different approaches
to the same problem.


---
class: center

## 51 Languages and counting

<img class="center-element" src="img/exercism-languages.png">

???

Exercism currently has 51 live languages tracks and has given the thumbs up
for a Gleam track.

The exercises need to be ported to Gleam and documentation needs to be
written, but once done we'll have a top notch experience for learning and
practicing Gleam.

Exercism is community run, open source, and very well organised so if you're
interested in contributing to Gleam or if you just want to learn some new
languages I would encourage you to check it out.

---
class: slide-bold middle center
<h1 style="font-size: 4em">Gleam ðŸ’• Erlang</h1>
???

As I said before Gleam's greatest strength is that it builds on top of Erlang,
and as such we want to integrate into the wider BEAM community as much as
possible.

Gleam uses the standard Erlang built tools and package management, we don't to
create an alternative, and we don't want to fracture the ecosystem.

It's straightforward to use Erlang libraries from Gleam, giving us access to a
healthy ecosystem of battle tested packages and libraries to use in our
programs.

We also want to give back to other BEAM languages, so it should be just as
easy to use Gleam libraries in them. An Erlang or Elixir programmer will be
able to import and use a Gleam library without needing to modify their build
pipeline, or having to learn anything about Gleam.

The aim is for Gleam to enrich the ecosystem further for users of all BEAM
languages, and to provide a new way of programming on the BEAM that will
hopefully draw in a wider collection of people.


---
class: middle, slide-bold
<img style="width: calc(100% - 580px); position: absolute; right: 30px; bottom: 10px" src="img/lucy-charcoal.svg">

<img style="width: 300px; margin: -110px -20px" src="img/gleam-charcoal.svg">

- https://gleam.run
- https://github.com/gleam-lang/gleam
- IRC `#gleam-lang` on Freenode

### Griffics' art

- https://www.griffics.com/

### Call me?

- twitter @louispilfold

???

That's all I've got to share today.

If any of this sounds interesting to you please do check out the website and
always feel free to message me on IRC, GitHub or Twitter with any questions
you might have.

Lastly I would like to say a huge thank you to Griffics for designing the
beautiful Gleam logo and Lucy the star. Go checkout his website, it's full of
lots of really fun and playful artwork.

Thank you very much for listening.


    </textarea>
    <script src="../vendor/remark-0.14.0.min.js"></script>
    <script>
var slideshow = remark.create({
  highlightStyle: "monokai",
  highlightLanguage: "remark",
  highlightLines: true,
});
    </script>
    <!-- <link href="https://fonts.googleapis.com/css?family=Karla" rel="stylesheet"> -->
  </body>
</html>
<!-- vi: ft=markdown
-->
